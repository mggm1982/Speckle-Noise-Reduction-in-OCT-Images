{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3ea1cf",
   "metadata": {},
   "source": [
    "# OCT Speckle Denoising (Supervised)\n",
    "\n",
    "Supervised OCT denoising pipeline that corrects frame jitter, builds pseudo-clean targets by aligning and median-averaging neighboring B-scans, trains a 2D UNet, and evaluates results using image-quality metrics and manual retinal-layer annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cc19a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.12.5 | packaged by Anaconda, Inc. | (main, Sep 12 2024, 13:22:57) [Clang 14.0.6 ]\n",
      "Working dir: /Users/kartikgoyal/Desktop/Speckle_Noise_Reduction\n",
      "DATA_ROOT (edit if incorrect): /Users/kartikgoyal/Desktop/Speckle_Noise_Reduction/Data\n",
      "OUT_DIR: /Users/kartikgoyal/Desktop/Speckle_Noise_Reduction/oct_denoise_outputs\n",
      "scikit-image available: True\n",
      "PyTorch available: True | torch.cuda available: False\n",
      "\n",
      "Found 1 TIFF(s), 1 .mat file(s), 520 Excel file(s).\n",
      " - Intensity.tif (size=136682861 bytes, md5=632aa6e9...)\n",
      "\n",
      "Example annotation files (first 12):\n",
      " - Intensity.tif100_x.xlsx\n",
      " - Intensity.tif100_y.xlsx\n",
      " - Intensity.tif101_x.xlsx\n",
      " - Intensity.tif101_y.xlsx\n",
      " - Intensity.tif102_x.xlsx\n",
      " - Intensity.tif102_y.xlsx\n",
      " - Intensity.tif103_x.xlsx\n",
      " - Intensity.tif103_y.xlsx\n",
      " - Intensity.tif104_x.xlsx\n",
      " - Intensity.tif104_y.xlsx\n",
      " - Intensity.tif105_x.xlsx\n",
      " - Intensity.tif105_y.xlsx\n",
      "\n",
      "Wrote dataset_discovery.json to oct_denoise_outputs/dataset_discovery.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports, config, basic dataset checks\n",
    "# Edit DATA_ROOT to point to your unzipped dataset folder before running.\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os, json, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# image I/O & processing\n",
    "try:\n",
    "    import tifffile\n",
    "except Exception as e:\n",
    "    raise ImportError(\"tifffile is required. Install with `pip install tifffile`\") from e\n",
    "\n",
    "from scipy.ndimage import shift as ndi_shift\n",
    "\n",
    "# try to import scikit-image utilities (registration, filters). If missing, show helpful message.\n",
    "_skimage_ok = True\n",
    "try:\n",
    "    from skimage.registration import phase_cross_correlation\n",
    "    from skimage import filters, restoration, metrics\n",
    "except Exception:\n",
    "    _skimage_ok = False\n",
    "    print(\"Warning: scikit-image not fully available. Install with `pip install scikit-image` to enable registration/filters.\")\n",
    "\n",
    "# Torch (used later for training)\n",
    "try:\n",
    "    import torch\n",
    "    _torch_ok = True\n",
    "except Exception:\n",
    "    _torch_ok = False\n",
    "    print(\"Warning: PyTorch not available. Install `torch`/`torchvision` if you plan to train a model in this notebook.\")\n",
    "\n",
    "# --------- USER CONFIG (edit these) ----------\n",
    "DATA_ROOT = Path(\"./Data\")        # <<< change this to your dataset folder (where Intensity.tif and Excel files live)\n",
    "BASE_TIF_NAME = \"Intensity.tif\"   # base used in many annotation filenames\n",
    "OUT_DIR = Path(\"./oct_denoise_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------- quick helpers ----------\n",
    "def md5(path, chunk=8192):\n",
    "    h = hashlib.md5()\n",
    "    with open(path, \"rb\") as f:\n",
    "        for c in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(c)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def find_files(root: Path):\n",
    "    tif_paths = sorted(list(root.rglob(\"*.tif\")) + list(root.rglob(\"*.tiff\")))\n",
    "    mat_paths = sorted(list(root.rglob(\"*.mat\")))\n",
    "    excel_paths = sorted(list(root.rglob(\"*.xls\")) + list(root.rglob(\"*.xlsx\")))\n",
    "    return tif_paths, mat_paths, excel_paths\n",
    "\n",
    "# --------- quick status print ----------\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "print(\"Working dir:\", Path.cwd())\n",
    "print(\"DATA_ROOT (edit if incorrect):\", DATA_ROOT.resolve())\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())\n",
    "print(\"scikit-image available:\", _skimage_ok)\n",
    "print(\"PyTorch available:\", _torch_ok, \"| torch.cuda available:\", (_torch_ok and torch.cuda.is_available()))\n",
    "\n",
    "# If DATA_ROOT doesn't exist, stop early (avoid long glob)\n",
    "if not DATA_ROOT.exists():\n",
    "    print(\"\\nERROR: DATA_ROOT does not exist ->\", DATA_ROOT.resolve())\n",
    "    print(\"Please set DATA_ROOT to the folder containing your unzipped dataset and re-run this cell.\")\n",
    "else:\n",
    "    tifs, mats, excels = find_files(DATA_ROOT)\n",
    "    print(f\"\\nFound {len(tifs)} TIFF(s), {len(mats)} .mat file(s), {len(excels)} Excel file(s).\")\n",
    "    if tifs:\n",
    "        for t in tifs[:6]:\n",
    "            try:\n",
    "                stat = t.stat()\n",
    "                print(\" -\", t.relative_to(DATA_ROOT), f\"(size={stat.st_size} bytes, md5={md5(t)[:8]}...)\")\n",
    "            except Exception:\n",
    "                print(\" -\", t.relative_to(DATA_ROOT))\n",
    "    if excels:\n",
    "        print(\"\\nExample annotation files (first 12):\")\n",
    "        for e in excels[:12]:\n",
    "            print(\" -\", e.relative_to(DATA_ROOT))\n",
    "    # Save a tiny JSON summary for downstream cells\n",
    "    summary = {\n",
    "        \"tif_count\": len(tifs),\n",
    "        \"mat_count\": len(mats),\n",
    "        \"excel_count\": len(excels),\n",
    "        \"tifs\": [str(p.relative_to(DATA_ROOT)) for p in tifs[:8]],\n",
    "        \"examples_excels\": [str(p.relative_to(DATA_ROOT)) for p in excels[:12]]\n",
    "    }\n",
    "    with open(OUT_DIR / \"dataset_discovery.json\", \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(\"\\nWrote dataset_discovery.json to\", OUT_DIR / \"dataset_discovery.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3ed6d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing annotation _x/_y Excel pairs (this may take a moment)...\n",
      "Found annotations for 260 slices.\n",
      "Saved annotations.json -> oct_denoise_outputs/annotations.json\n",
      "Saved annotation_summary.json -> oct_denoise_outputs/annotation_summary.json\n",
      "Saved annotation histogram -> oct_denoise_outputs/annotation_histogram.png\n",
      "Using TIFF for overlays: Intensity.tif\n",
      "Saved representative slice -> oct_denoise_outputs/representative_slice.png\n",
      "Saved overlay -> oct_denoise_outputs/overlay_first.png\n",
      "Saved overlay -> oct_denoise_outputs/overlay_median.png\n",
      "Saved overlay -> oct_denoise_outputs/overlay_max.png\n",
      "\n",
      "Cell complete. Check files in OUT_DIR: /Users/kartikgoyal/Desktop/Speckle_Noise_Reduction/oct_denoise_outputs\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Parse annotation Excel pairs, save annotations.json + summary, make histogram + overlay images\n",
    "# Requires DATA_ROOT and OUT_DIR defined in previous cell.\n",
    "\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "\n",
    "# safety checks\n",
    "if not Path(DATA_ROOT).exists():\n",
    "    raise FileNotFoundError(f\"DATA_ROOT does not exist: {DATA_ROOT}\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def find_xy_pairs(root: Path, base_hint=\"Intensity.tif\"):\n",
    "    \"\"\"\n",
    "    Find pairs of Excel files that are annotations:\n",
    "    - prefer files matching <base_hint><idx>_x.xlsx / _y.xlsx\n",
    "    - fallback to any files ending with _x.(xls|xlsx) with a corresponding _y file (matching digit group)\n",
    "    Returns dict mapping slice_index -> list of (x_list, y_list) curves\n",
    "    \"\"\"\n",
    "    root = Path(root)\n",
    "    x_files = sorted([p for p in root.rglob(\"*.xlsx\")] + [p for p in root.rglob(\"*.xls\")])\n",
    "    # filter x-files\n",
    "    x_files = [p for p in x_files if re.search(r\"_x(\\.xls|\\.xlsx)$\", str(p.name), flags=re.IGNORECASE)]\n",
    "    pairs = {}\n",
    "    for fx in x_files:\n",
    "        name = fx.name\n",
    "        # try extract index in form base_hint<digits> or <digits>_x\n",
    "        m = re.search(rf\"{re.escape(base_hint)}(\\d+)\", name) or re.search(r\"(\\d+)(?=_x\\.)\", name) or re.search(r\"(\\d+)\", name)\n",
    "        if not m:\n",
    "            # fallback: try to find any file with same prefix but _y replacement\n",
    "            possible = list(root.rglob(name.replace(\"_x\", \"_y\")))\n",
    "            fy = possible[0] if possible else None\n",
    "            idx = None\n",
    "        else:\n",
    "            idx = int(m.group(1))\n",
    "            # build likely y filename candidates\n",
    "            cand1 = fx.with_name(re.sub(r\"_x(\\.xls|\\.xlsx)$\", \"_y\\\\1\", name, flags=re.IGNORECASE))\n",
    "            cand2 = fx.with_name(re.sub(r\"_x\", \"_y\", name, flags=re.IGNORECASE))\n",
    "            fy = cand1 if cand1.exists() else (cand2 if cand2.exists() else None)\n",
    "            if fy is None:\n",
    "                # try search for any file containing same digit group and '_y'\n",
    "                matches = list(root.rglob(f\"*{idx}*_y.*\"))\n",
    "                fy = matches[0] if matches else None\n",
    "        if fy is None:\n",
    "            continue\n",
    "        # read x,y sheets (no header expected)\n",
    "        try:\n",
    "            xdf = pd.read_excel(fx, header=None)\n",
    "            ydf = pd.read_excel(fy, header=None)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not read pair {fx.relative_to(root)} / {fy.relative_to(root)}: {e}\")\n",
    "            continue\n",
    "        curves = []\n",
    "        for r in range(min(xdf.shape[0], ydf.shape[0])):\n",
    "            xrow = xdf.iloc[r].dropna().values\n",
    "            yrow = ydf.iloc[r].dropna().values\n",
    "            if xrow.size == 0 or yrow.size == 0: \n",
    "                continue\n",
    "            if xrow.size != yrow.size:\n",
    "                n = min(xrow.size, yrow.size)\n",
    "                xrow = xrow[:n]; yrow = yrow[:n]\n",
    "            try:\n",
    "                xlist = [float(v) for v in xrow]\n",
    "                ylist = [float(v) for v in yrow]\n",
    "            except:\n",
    "                continue\n",
    "            if len(xlist) >= 2:\n",
    "                curves.append([xlist, ylist])\n",
    "        if curves:\n",
    "            pairs.setdefault(int(idx), []).extend(curves)\n",
    "    return pairs\n",
    "\n",
    "print(\"Parsing annotation _x/_y Excel pairs (this may take a moment)...\")\n",
    "annotations = find_xy_pairs(Path(DATA_ROOT), base_hint=BASE_TIF_NAME)\n",
    "n_annotated = len(annotations)\n",
    "print(f\"Found annotations for {n_annotated} slices.\")\n",
    "\n",
    "# Save annotations.json (keys as strings)\n",
    "ann_path = OUT_DIR / \"annotations.json\"\n",
    "with open(ann_path, \"w\") as f:\n",
    "    json.dump({str(k): annotations[k] for k in sorted(annotations.keys())}, f, indent=2)\n",
    "print(\"Saved annotations.json ->\", ann_path)\n",
    "\n",
    "# Save annotation summary (counts per slice)\n",
    "summary = {str(k): len(v) for k,v in annotations.items()}\n",
    "summary_path = OUT_DIR / \"annotation_summary.json\"\n",
    "with open(summary_path, \"w\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(\"Saved annotation_summary.json ->\", summary_path)\n",
    "\n",
    "# Histogram of annotation coverage\n",
    "counts = np.array(list(summary.values())) if summary else np.array([0])\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.hist(counts, bins=range(0, int(counts.max() if counts.size else 1)+2), align='left', rwidth=0.8)\n",
    "plt.xlabel(\"Number of traced curves (per slice)\")\n",
    "plt.ylabel(\"Number of slices\")\n",
    "plt.title(\"Annotation coverage\")\n",
    "plt.grid(axis='y', alpha=0.4)\n",
    "hist_path = OUT_DIR / \"annotation_histogram.png\"\n",
    "plt.savefig(hist_path, bbox_inches='tight', dpi=150)\n",
    "plt.close()\n",
    "print(\"Saved annotation histogram ->\", hist_path)\n",
    "\n",
    "# Create representative slice and overlays (if a TIFF exists)\n",
    "tif_list = sorted(list(Path(DATA_ROOT).rglob(\"*.tif\")) + list(Path(DATA_ROOT).rglob(\"*.tiff\")))\n",
    "if tif_list:\n",
    "    tif0 = tif_list[0]\n",
    "    print(\"Using TIFF for overlays:\", tif0.relative_to(DATA_ROOT))\n",
    "    stack = tifffile.imread(str(tif0)).astype(np.float32)\n",
    "    # representative middle slice\n",
    "    mid = stack.shape[0] // 2\n",
    "    rep = stack[mid]\n",
    "    rep_norm = (rep - rep.min()) / (rep.max() - rep.min() + 1e-9)\n",
    "    rep_path = OUT_DIR / \"representative_slice.png\"\n",
    "    plt.imsave(str(rep_path), rep_norm, cmap=\"gray\")\n",
    "    print(\"Saved representative slice ->\", rep_path)\n",
    "    # overlays: pick first, median, and most-annotated slices if available\n",
    "    if annotations:\n",
    "        sorted_idxs = sorted(annotations.keys())\n",
    "        first_idx = sorted_idxs[0]\n",
    "        median_idx = sorted_idxs[len(sorted_idxs)//2]\n",
    "        max_idx = max(sorted_idxs, key=lambda k: len(annotations[k]))\n",
    "        def save_overlay(idx, ann_list, name):\n",
    "            if idx < 0 or idx >= stack.shape[0]:\n",
    "                print(\"Skipping overlay for out-of-range index\", idx)\n",
    "                return\n",
    "            img = stack[idx]\n",
    "            norm = (img - img.min())/(img.max()-img.min()+1e-9)\n",
    "            plt.figure(figsize=(8,6))\n",
    "            plt.imshow(norm, cmap='gray')\n",
    "            for curve in ann_list:\n",
    "                x,y = curve\n",
    "                plt.plot(x, y, '-r', linewidth=1)\n",
    "            plt.axis('off')\n",
    "            p = OUT_DIR / name\n",
    "            plt.savefig(p, bbox_inches='tight', dpi=150)\n",
    "            plt.close()\n",
    "            print(\"Saved overlay ->\", p)\n",
    "        save_overlay(first_idx, annotations[first_idx], \"overlay_first.png\")\n",
    "        save_overlay(median_idx, annotations[median_idx], \"overlay_median.png\")\n",
    "        save_overlay(max_idx, annotations[max_idx], \"overlay_max.png\")\n",
    "    else:\n",
    "        print(\"No annotations available to create overlays.\")\n",
    "else:\n",
    "    print(\"No TIFF files found under DATA_ROOT; overlays and representative slice not created.\")\n",
    "\n",
    "print(\"\\nCell complete. Check files in OUT_DIR:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9c0e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TIFF: Intensity.tif\n",
      "Stack shape (slices, H, W): (339, 806, 500)\n",
      "Reference slice index: 169\n",
      "  processed slice 0/339  shift=[-14.1 -20.7]  err=0.1667\n",
      "  processed slice 50/339  shift=[-48.    3.9]  err=0.1517\n",
      "  processed slice 100/339  shift=[-25.  -32.9]  err=0.1403\n",
      "  processed slice 150/339  shift=[-51.9  54.9]  err=0.1732\n",
      "  processed slice 200/339  shift=[ 1.7 -7. ]  err=0.1053\n",
      "  processed slice 250/339  shift=[-53.   32.9]  err=0.2133\n",
      "  processed slice 300/339  shift=[42.2 45.9]  err=0.1674\n",
      "Done in 36.7s\n",
      "Saved CSV -> oct_denoise_outputs/estimated_shifts_all_fixed.csv\n",
      "Saved summary -> oct_denoise_outputs/shifts_summary_fixed.json\n",
      "Recommendation: Register slices before averaging (median shifts > ~1.5 px).\n",
      "Saved plot -> oct_denoise_outputs/shifts_plot_fixed.png\n",
      "\n",
      "Sample (first 8) slice shifts+errors:\n",
      " slice   0: shift=(-14.10,-20.70)  error=0.1667\n",
      " slice   1: shift=( 31.70, 63.10)  error=0.1735\n",
      " slice   2: shift=(-14.10, 54.80)  error=0.1567\n",
      " slice   3: shift=(-76.20, 36.00)  error=0.1825\n",
      " slice   4: shift=(-31.10, 48.00)  error=0.1574\n",
      " slice   5: shift=(-82.80,-30.90)  error=0.1862\n",
      " slice   6: shift=(-47.30, -6.20)  error=0.1648\n",
      " slice   7: shift=(  1.90,-96.00)  error=0.1770\n"
     ]
    }
   ],
   "source": [
    "# Cell 3 (fixed): Estimate frame-to-frame jitter (shifts) with robust preprocessing and fallback error\n",
    "# Writes: OUT_DIR/estimated_shifts_all_fixed.csv, OUT_DIR/shifts_plot_fixed.png, OUT_DIR/shifts_summary_fixed.json\n",
    "\n",
    "import numpy as np, csv, json, time\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import shift as ndi_shift\n",
    "import tifffile\n",
    "\n",
    "# registration routine\n",
    "try:\n",
    "    from skimage.registration import phase_cross_correlation\n",
    "except Exception:\n",
    "    raise ImportError(\"skimage.registration.phase_cross_correlation required (pip install scikit-image)\")\n",
    "\n",
    "# PARAMETERS\n",
    "UPSAMPLE_FACTOR = 10     # subpixel precision (reduce to 5 if slow)\n",
    "REFERENCE = \"center\"     # \"center\" or integer index\n",
    "MAX_FRAMES = None        # optionally limit processing for speed\n",
    "WINDOW_APPLY = True      # apply Hann windowing to reduce edge effects\n",
    "NORMALIZE_FOR_REG = True # subtract mean and divide by std before registration\n",
    "\n",
    "# Paths (reuse variables from cell1)\n",
    "DATA_ROOT = Path(DATA_ROOT) if isinstance(DATA_ROOT, (str, Path)) else Path(\"./data\")\n",
    "OUT_DIR  = Path(OUT_DIR)  if isinstance(OUT_DIR, (str, Path)) else Path(\"./oct_denoise_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Find TIFF\n",
    "tif_list = sorted(list(DATA_ROOT.rglob(\"*.tif\")) + list(DATA_ROOT.rglob(\"*.tiff\")))\n",
    "if not tif_list:\n",
    "    raise FileNotFoundError(f\"No TIFF files found under DATA_ROOT: {DATA_ROOT}\")\n",
    "tif_path = tif_list[0]\n",
    "print(\"Using TIFF:\", tif_path.relative_to(DATA_ROOT))\n",
    "\n",
    "# Load stack\n",
    "stack = tifffile.imread(str(tif_path)).astype(np.float32)\n",
    "n_slices = stack.shape[0]\n",
    "print(\"Stack shape (slices, H, W):\", stack.shape)\n",
    "\n",
    "# choose frames\n",
    "if MAX_FRAMES is None:\n",
    "    idxs = np.arange(n_slices)\n",
    "else:\n",
    "    idxs = np.arange(min(MAX_FRAMES, n_slices))\n",
    "\n",
    "# choose reference index\n",
    "if REFERENCE == \"center\":\n",
    "    ref_idx = n_slices // 2\n",
    "elif isinstance(REFERENCE, int):\n",
    "    ref_idx = int(REFERENCE)\n",
    "else:\n",
    "    ref_idx = 0\n",
    "print(\"Reference slice index:\", ref_idx)\n",
    "\n",
    "# helper: hann window 2D\n",
    "def hann2d(h, w):\n",
    "    wy = np.hanning(h)\n",
    "    wx = np.hanning(w)\n",
    "    return np.outer(wy, wx)\n",
    "\n",
    "eps = 1e-9\n",
    "\n",
    "# preprocess function for registration\n",
    "def prep_for_reg(img):\n",
    "    # convert to float64\n",
    "    im = img.astype(np.float64)\n",
    "    # subtract mean and scale by std to avoid large DC component\n",
    "    if NORMALIZE_FOR_REG:\n",
    "        std = im.std()\n",
    "        if std < eps:\n",
    "            im = im - im.mean()\n",
    "        else:\n",
    "            im = (im - im.mean()) / (std + eps)\n",
    "    # apply windowing to reduce edge artifacts (helpful for FFT-based methods)\n",
    "    if WINDOW_APPLY:\n",
    "        h,w = im.shape\n",
    "        win = hann2d(h,w)\n",
    "        im = im * win\n",
    "    return im\n",
    "\n",
    "# arrays to fill\n",
    "shifts = np.zeros((n_slices,2), dtype=float)\n",
    "errors = np.zeros((n_slices,), dtype=float)\n",
    "\n",
    "ref_raw = stack[ref_idx]\n",
    "ref_p = prep_for_reg(ref_raw)\n",
    "\n",
    "start = time.time()\n",
    "for i in idxs:\n",
    "    if i == ref_idx:\n",
    "        shifts[i] = (0.0, 0.0)\n",
    "        errors[i] = 0.0\n",
    "        continue\n",
    "    mov_raw = stack[i]\n",
    "    mov_p = prep_for_reg(mov_raw)\n",
    "\n",
    "    # try subpixel registration; if it raises, fallback to upsample=1\n",
    "    try:\n",
    "        shift, err, diffphase = phase_cross_correlation(ref_p, mov_p, upsample_factor=UPSAMPLE_FACTOR)\n",
    "    except Exception:\n",
    "        shift, err, diffphase = phase_cross_correlation(ref_p, mov_p, upsample_factor=1)\n",
    "\n",
    "    # If shift contains NaN or large values, clamp it\n",
    "    if not np.isfinite(shift).all():\n",
    "        shift = np.array((0.0, 0.0))\n",
    "    shifts[i] = shift\n",
    "\n",
    "    # If skimage gave a valid error (0..1, finite, and not exactly 1.0), use it; otherwise compute robust fallback\n",
    "    use_err = None\n",
    "    if np.isfinite(err) and (err >= 0.0) and (err < 0.9999):\n",
    "        use_err = float(err)\n",
    "    else:\n",
    "        # fallback: apply the shift to the raw moving image and compute normalized RMSE vs raw reference\n",
    "        try:\n",
    "            moved_full = ndi_shift(mov_raw, shift=shift, order=1, mode='nearest')\n",
    "            # compute normalized RMSE: sqrt(mean((ref - moved)^2)) / (ref.max()-ref.min())\n",
    "            denom = (ref_raw.max() - ref_raw.min()) if (ref_raw.max() - ref_raw.min())>eps else ref_raw.std()+eps\n",
    "            nrmse = np.sqrt(np.mean((ref_raw - moved_full)**2)) / (denom + eps)\n",
    "            # clamp to [0,1]\n",
    "            nrmse = float(min(max(nrmse, 0.0), 1.0))\n",
    "            use_err = nrmse\n",
    "        except Exception:\n",
    "            use_err = 1.0\n",
    "    errors[i] = use_err\n",
    "\n",
    "    # progress\n",
    "    if (i % 50) == 0:\n",
    "        print(f\"  processed slice {i}/{n_slices}  shift={shifts[i]}  err={errors[i]:.4f}\")\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Done in {(end-start):.1f}s\")\n",
    "\n",
    "# Save CSV with fixed results\n",
    "csv_path = OUT_DIR / \"estimated_shifts_all_fixed.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"slice_index\",\"shift_y\",\"shift_x\",\"error\"])\n",
    "    for i in range(n_slices):\n",
    "        writer.writerow([int(i), float(shifts[i,0]), float(shifts[i,1]), float(errors[i])])\n",
    "print(\"Saved CSV ->\", csv_path)\n",
    "\n",
    "# Save summary JSON and a recommendation\n",
    "dy_med = float(np.median(np.abs(shifts[:,0])))\n",
    "dx_med = float(np.median(np.abs(shifts[:,1])))\n",
    "dy_max = float(np.max(np.abs(shifts[:,0])))\n",
    "dx_max = float(np.max(np.abs(shifts[:,1])))\n",
    "\n",
    "summary = {\n",
    "    \"tif_used\": str(tif_path.relative_to(DATA_ROOT)),\n",
    "    \"n_slices\": int(n_slices),\n",
    "    \"reference_index\": int(ref_idx),\n",
    "    \"upsample_factor\": int(UPSAMPLE_FACTOR),\n",
    "    \"median_abs_shift_y\": dy_med,\n",
    "    \"median_abs_shift_x\": dx_med,\n",
    "    \"max_abs_shift_y\": dy_max,\n",
    "    \"max_abs_shift_x\": dx_max\n",
    "}\n",
    "summary[\"recommendation\"] = (\"Register slices before averaging (median shifts > ~1.5 px).\"\n",
    "                            if (dy_med > 1.5 or dx_med > 1.5) else\n",
    "                            \"Registration optional (median shifts small).\")\n",
    "\n",
    "json_path = OUT_DIR / \"shifts_summary_fixed.json\"\n",
    "with open(json_path, \"w\") as jf:\n",
    "    json.dump(summary, jf, indent=2)\n",
    "print(\"Saved summary ->\", json_path)\n",
    "print(\"Recommendation:\", summary[\"recommendation\"])\n",
    "\n",
    "# Plot shifts and errors\n",
    "plt.figure(figsize=(11,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(shifts[:,0], label=\"shift_y (vertical)\"); plt.plot(shifts[:,1], label=\"shift_x (horizontal)\")\n",
    "plt.axhline(0, color='k', linewidth=0.5); plt.legend(); plt.title(\"Estimated shifts (px)\"); plt.xlabel(\"slice\"); plt.ylabel(\"pixels\"); plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(errors, label=\"error (NRMSE-like)\"); plt.ylim(0,1.0); plt.title(\"Per-slice error\"); plt.xlabel(\"slice\"); plt.ylabel(\"error\"); plt.grid(True)\n",
    "\n",
    "plot_path = OUT_DIR / \"shifts_plot_fixed.png\"\n",
    "plt.tight_layout(); plt.savefig(plot_path, dpi=150, bbox_inches=\"tight\"); plt.close()\n",
    "print(\"Saved plot ->\", plot_path)\n",
    "\n",
    "# Print a few sample rows for quick sanity check\n",
    "print(\"\\nSample (first 8) slice shifts+errors:\")\n",
    "for i in range(min(8, n_slices)):\n",
    "    print(f\" slice {i:3d}: shift=({shifts[i,0]:6.2f},{shifts[i,1]:6.2f})  error={errors[i]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daf99641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stack: Intensity.tif shape: (339, 806, 500)\n",
      "Found annotations.json; generating pseudos for annotated slices: 260\n",
      "DEBUG sample (first processed slice): center= 29\n",
      "  neighbor_idxs: [25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
      "  used_idxs sample: [25, 26, 27, 28, 29, 30, 31, 32]\n",
      "  shifts_used sample: [[-1.3333333333333333, 0.3333333333333333], [-0.5, 1.6666666666666667], [0.0, 0.16666666666666666], [0.0, 0.0], [0.0, 0.0], [0.0, 0.0], [-0.16666666666666666, 0.3333333333333333], [0.8333333333333334, -1.5]]\n",
      "  errs_used sample: [0.506396777099378, 0.475615585235201, 0.46715252049187744, 0.37047922306446196, 0.0, 0.36705796436596533, 0.44725449460606537, 0.48843346827124645]\n",
      "Processed 50/260 target slices (last center=107)\n",
      "Processed 100/260 target slices (last center=159)\n",
      "Processed 150/260 target slices (last center=209)\n",
      "Processed 200/260 target slices (last center=259)\n",
      "Processed 250/260 target slices (last center=310)\n",
      "Saved improved pseudos -> oct_denoise_outputs/pseudo_clean_improved.npz\n",
      "Saved summary -> oct_denoise_outputs/pseudo_improved_summary.json\n",
      "Saved QA visuals (up to 6) -> oct_denoise_outputs/pseudo_improved_vis\n",
      "Done. Total time: 325.2s\n"
     ]
    }
   ],
   "source": [
    "# Cell: Generate improved pseudo-targets with robust registration, confidence maps, and optional NLM post-filter\n",
    "# (Drop-in replacement â€” minimal safe improvements: robust manual error, exclude ref from med/MAD, optional cc normalization)\n",
    "import time, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy.ndimage import shift as ndi_shift\n",
    "from scipy.ndimage import median_filter\n",
    "from skimage.registration import phase_cross_correlation\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional fast NLM\n",
    "try:\n",
    "    from skimage.restoration import denoise_nl_means\n",
    "    _HAS_NLM = True\n",
    "except Exception:\n",
    "    _HAS_NLM = False\n",
    "\n",
    "# ---------- PARAMETERS (tune these) ----------\n",
    "OUT_DIR = Path(OUT_DIR) if isinstance(OUT_DIR, (str, Path)) else Path(\"./oct_denoise_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT = Path(DATA_ROOT) if isinstance(DATA_ROOT, (str, Path)) else Path(\"./data\")\n",
    "\n",
    "RADIUS = 4                # neighbors on each side -> up to 2*RADIUS+1 frames\n",
    "UPSAMPLE_FACTOR = 6       # subpixel precision for phase_cross_correlation\n",
    "WINDOW_APPLY = True       # apply Hann window for registration stability (you enabled this)\n",
    "NORMALIZE_FOR_REG = True  # subtract mean & divide by std before reg (you enabled this)\n",
    "MIN_FRAMES = 3            # need at least this many aligned frames to accept pseudo\n",
    "MAX_SHIFT_PIX = 80.0      # clamp extreme shifts (px)\n",
    "ERR_MAD_MULT = 2.5        # threshold = median_err + ERR_MAD_MULT * mad_err\n",
    "ERR_CLIP = 10.0           # cap manual_err to avoid huge outliers dominating MAD\n",
    "NLM_POSTPROCESS = True and _HAS_NLM  # apply small NLM to pseudos if skimage present\n",
    "NLM_H = 0.05              # very conservative\n",
    "NLM_PATCH_SIZE = 5\n",
    "NLM_PATCH_DISTANCE = 6\n",
    "SAVE_VIS = True\n",
    "VIS_COUNT = 6\n",
    "\n",
    "# output filenames\n",
    "OUT_NPZ = OUT_DIR / \"pseudo_clean_improved.npz\"\n",
    "SUMMARY_JSON = OUT_DIR / \"pseudo_improved_summary.json\"\n",
    "VIS_DIR = OUT_DIR / \"pseudo_improved_vis\"\n",
    "VIS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "eps = 1e-9\n",
    "def hann2d(h,w):\n",
    "    return np.outer(np.hanning(h), np.hanning(w))\n",
    "\n",
    "def prep_for_reg(img):\n",
    "    im = img.astype(np.float64)\n",
    "    if NORMALIZE_FOR_REG:\n",
    "        s = im.std()\n",
    "        if s < eps:\n",
    "            im = im - im.mean()\n",
    "        else:\n",
    "            im = (im - im.mean())/(s + eps)\n",
    "    if WINDOW_APPLY:\n",
    "        im = im * hann2d(im.shape[0], im.shape[1])\n",
    "    return im\n",
    "\n",
    "def mad(a):\n",
    "    med = np.median(a)\n",
    "    return np.median(np.abs(a - med))\n",
    "\n",
    "# ---------- load stack & optional annotations ----------\n",
    "tif_list = sorted(list(Path(DATA_ROOT).rglob(\"*.tif\")) + list(Path(DATA_ROOT).rglob(\"*.tiff\")))\n",
    "if not tif_list:\n",
    "    raise FileNotFoundError(\"No TIFF found under DATA_ROOT: \" + str(DATA_ROOT))\n",
    "tif_path = tif_list[0]\n",
    "stack = tifffile.imread(str(tif_path)).astype(np.float32)   # (S,H,W)\n",
    "S, H, W = stack.shape\n",
    "print(\"Loaded stack:\", tif_path.name, \"shape:\", stack.shape)\n",
    "\n",
    "# if you want to restrict pseudos to annotated slices (earlier workflow), load annotations.json in OUT_DIR\n",
    "ann_path = OUT_DIR / \"annotations.json\"\n",
    "if ann_path.exists():\n",
    "    with open(ann_path, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    target_slices = sorted([int(k) for k in annotations.keys()])\n",
    "    print(\"Found annotations.json; generating pseudos for annotated slices:\", len(target_slices))\n",
    "else:\n",
    "    target_slices = list(range(S))\n",
    "    print(\"No annotations found in OUT_DIR; generating pseudos for all slices:\", len(target_slices))\n",
    "\n",
    "# ---------- main loop ----------\n",
    "indices_out = []\n",
    "imgs_out = []\n",
    "confs_out = []\n",
    "used_frames_out = []\n",
    "shifts_out = []\n",
    "errs_out = []\n",
    "\n",
    "summary = {\"created\": [], \"params\": {\n",
    "    \"RADIUS\": RADIUS, \"UPSAMPLE_FACTOR\": UPSAMPLE_FACTOR,\n",
    "    \"MIN_FRAMES\": MIN_FRAMES, \"ERR_MAD_MULT\": ERR_MAD_MULT, \"NLM_POSTPROCESS\": bool(NLM_POSTPROCESS)\n",
    "}}\n",
    "\n",
    "t0_all = time.time()\n",
    "vis_saved = 0\n",
    "\n",
    "# small diagnostic: print first slice neighbor errs to confirm behavior\n",
    "DEBUG_PRINT_FIRST = True\n",
    "printed_debug = False\n",
    "\n",
    "for count, center in enumerate(target_slices):\n",
    "    lo = max(0, center - RADIUS)\n",
    "    hi = min(S-1, center + RADIUS)\n",
    "    neighbor_idxs = list(range(lo, hi+1))\n",
    "\n",
    "    ref_raw = stack[center].astype(np.float32)\n",
    "    ref_p = prep_for_reg(ref_raw)\n",
    "\n",
    "    aligned = []\n",
    "    shifts = []\n",
    "    errs = []\n",
    "    used_idxs = []\n",
    "\n",
    "    # register neighbors -> ref\n",
    "    for j in neighbor_idxs:\n",
    "        mov_raw = stack[j].astype(np.float32)\n",
    "        mov_p = prep_for_reg(mov_raw)\n",
    "\n",
    "        # try to call with explicit normalization if supported (some skimage versions accept it)\n",
    "        try:\n",
    "            shift, err, _ = phase_cross_correlation(ref_p, mov_p, upsample_factor=UPSAMPLE_FACTOR, normalization=None)\n",
    "        except TypeError:\n",
    "            # older skimage may not support 'normalization' kwarg\n",
    "            try:\n",
    "                shift, err, _ = phase_cross_correlation(ref_p, mov_p, upsample_factor=UPSAMPLE_FACTOR)\n",
    "            except Exception:\n",
    "                shift, err, _ = phase_cross_correlation(ref_p, mov_p, upsample_factor=1)\n",
    "        except Exception:\n",
    "            # any other runtime error fallback\n",
    "            try:\n",
    "                shift, err, _ = phase_cross_correlation(ref_p, mov_p, upsample_factor=1)\n",
    "            except Exception:\n",
    "                # final fallback: zero shift / huge err\n",
    "                shift = np.array([0.0, 0.0], dtype=float)\n",
    "                err = 1e6\n",
    "\n",
    "        # sanitize err from phase_cross_correlation (may be unreliable in some skimage versions)\n",
    "        if not np.isfinite(err):\n",
    "            err = 1e6\n",
    "        shift = np.array(shift, dtype=float)\n",
    "        # clamp huge shifts -> mark as bad\n",
    "        if np.any(np.abs(shift) > MAX_SHIFT_PIX):\n",
    "            err = 1e6\n",
    "\n",
    "        if err < 1e6:\n",
    "            # compute manual residual/error on the preprocessed images (robust)\n",
    "            aligned_test = ndi_shift(mov_p, shift=(-shift[0], -shift[1]), order=1, mode='reflect')\n",
    "            resid = (ref_p - aligned_test).ravel()\n",
    "            # prefer RMS normalization (norm(resid) / norm(ref_p))\n",
    "            num = float(np.linalg.norm(resid))\n",
    "            den = float(np.linalg.norm(ref_p.ravel()) + eps)\n",
    "            manual_err = num / den\n",
    "            if not np.isfinite(manual_err):\n",
    "                manual_err = 1e6\n",
    "            # clip extreme manual errors to avoid dominating MAD\n",
    "            manual_err = float(min(manual_err, ERR_CLIP))\n",
    "\n",
    "            # apply shift to original raw image (not preprocessed) and record results\n",
    "            aligned_full = ndi_shift(mov_raw, shift=(-shift[0], -shift[1]), order=1, mode='reflect')\n",
    "            aligned.append(aligned_full)\n",
    "            shifts.append(shift.tolist())\n",
    "            errs.append(manual_err)   # <- use manual_err\n",
    "            used_idxs.append(int(j))\n",
    "        else:\n",
    "            # ignore badly aligned frame\n",
    "            pass\n",
    "\n",
    "    # If no aligned frames (unexpected), fallback: use reference only\n",
    "    if len(aligned) == 0:\n",
    "        pseudo = ref_raw.copy()\n",
    "        conf = np.zeros_like(pseudo, dtype=np.float32)\n",
    "        used = [int(center)]\n",
    "        shifts_used = [[0.0,0.0]]\n",
    "        errs_used = [float(0.0)]\n",
    "        med_err = None\n",
    "        mad_err = None\n",
    "    else:\n",
    "        # robust per-neighbor error thresholding: compute median & MAD of errs and reject outliers\n",
    "        errs_arr = np.array(errs, dtype=float)\n",
    "        # exclude exact-zero entries (typically the reference) when computing med/MAD so zeros don't bias stats\n",
    "        errs_for_stats = errs_arr[errs_arr > 0.0]\n",
    "        if errs_for_stats.size == 0:\n",
    "            # if nothing non-zero, fall back to full array\n",
    "            errs_for_stats = errs_arr.copy()\n",
    "\n",
    "        med_err = float(np.median(errs_for_stats))\n",
    "        mad_err = float(mad(errs_for_stats))\n",
    "        thr = med_err + ERR_MAD_MULT * (mad_err + 1e-9)\n",
    "\n",
    "        # choose frames with err <= thr (always keep the reference if present in used_idxs)\n",
    "        keep_mask = errs_arr <= thr\n",
    "        # if after rejecting we have fewer than MIN_FRAMES, relax threshold to keep top MIN_FRAMES closest\n",
    "        if keep_mask.sum() < MIN_FRAMES:\n",
    "            order = np.argsort(errs_arr)\n",
    "            keep_idx = order[:min(len(order), MIN_FRAMES)]\n",
    "            keep_mask = np.zeros_like(keep_mask)\n",
    "            keep_mask[keep_idx] = True\n",
    "\n",
    "        aligned_keep = [aligned[i] for i in range(len(aligned)) if keep_mask[i]]\n",
    "        used = [used_idxs[i] for i in range(len(used_idxs)) if keep_mask[i]]\n",
    "        shifts_used = [shifts[i] for i in range(len(shifts)) if keep_mask[i]]\n",
    "        errs_used = [errs[i] for i in range(len(errs)) if keep_mask[i]]\n",
    "\n",
    "        if len(aligned_keep) == 0:\n",
    "            pseudo = ref_raw.copy()\n",
    "            conf = np.zeros_like(pseudo, dtype=np.float32)\n",
    "        else:\n",
    "            A = np.stack(aligned_keep, axis=0).astype(np.float32)  # (K,H,W)\n",
    "            # median pseudo is edge-preserving\n",
    "            pseudo_med = np.median(A, axis=0).astype(np.float32)\n",
    "            # per-pixel MAD -> confidence: smaller MAD -> higher confidence\n",
    "            pixel_mad = np.median(np.abs(A - np.expand_dims(pseudo_med,0)), axis=0)\n",
    "            # normalize mad to [0,1] (invert -> conf)\n",
    "            # use robust scale: instead of max which can be impacted by outliers, use 99th percentile\n",
    "            pm_scale = np.percentile(pixel_mad.ravel(), 99.0)\n",
    "            pm_max = pm_scale if pm_scale > 0 else 1.0\n",
    "            conf = 1.0 - (pixel_mad / (pm_max + eps))\n",
    "            conf = np.clip(conf, 0.0, 1.0)\n",
    "\n",
    "            # optional light NLM on normalized pseudo (low strength)\n",
    "            if NLM_POSTPROCESS:\n",
    "                try:\n",
    "                    pseudo01 = (pseudo_med - pseudo_med.min())/(pseudo_med.max()-pseudo_med.min()+eps)\n",
    "                    # skimage API differences: keep the familiar args (fast_mode True, multichannel False)\n",
    "                    nlm01 = denoise_nl_means(pseudo01, patch_size=NLM_PATCH_SIZE,\n",
    "                                             patch_distance=NLM_PATCH_DISTANCE, h=NLM_H, fast_mode=True, multichannel=False)\n",
    "                    # rescale to original pseudo range\n",
    "                    pseudo = (nlm01 - nlm01.min())/(nlm01.max()-nlm01.min()+eps) * (pseudo_med.max()-pseudo_med.min()) + pseudo_med.min()\n",
    "                except Exception:\n",
    "                    pseudo = pseudo_med\n",
    "            else:\n",
    "                pseudo = pseudo_med\n",
    "\n",
    "    # record outputs\n",
    "    indices_out.append(int(center))\n",
    "    imgs_out.append(pseudo.astype(np.float32))\n",
    "    confs_out.append(conf.astype(np.float32))\n",
    "    used_frames_out.append(used)\n",
    "    shifts_out.append(shifts_used)\n",
    "    errs_out.append(errs_used)\n",
    "\n",
    "    # summary stats for this slice\n",
    "    summary[\"created\"].append({\n",
    "        \"idx\": int(center),\n",
    "        \"n_neighbors_found\": int(len(used_idxs)),\n",
    "        \"n_neighbors_used\": int(len(used)),\n",
    "        \"median_err_before_filter\": float(med_err) if med_err is not None else None,\n",
    "        \"mad_err_before_filter\": float(mad_err) if med_err is not None else None,\n",
    "        \"shifts_used\": shifts_used,\n",
    "        \"errs_used\": errs_used\n",
    "    })\n",
    "\n",
    "    # save a few PNGs for QA\n",
    "    if SAVE_VIS and vis_saved < VIS_COUNT:\n",
    "        norm_ref = (ref_raw - ref_raw.min())/(ref_raw.max()-ref_raw.min()+eps)\n",
    "        norm_pseudo = (pseudo - pseudo.min())/(pseudo.max()-pseudo.min()+eps)\n",
    "        fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "        axs[0].imshow(norm_ref, cmap='gray'); axs[0].set_title(f\"ref {center}\"); axs[0].axis('off')\n",
    "        axs[1].imshow(norm_pseudo, cmap='gray'); axs[1].set_title(\"pseudo (median+opt)\"); axs[1].axis('off')\n",
    "        axs[2].imshow(conf, cmap='viridis'); axs[2].set_title(\"confidence\"); axs[2].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(VIS_DIR / f\"pseudo_vis_{center:04d}.png\", dpi=150, bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        vis_saved += 1\n",
    "\n",
    "    # small periodic diagnostics\n",
    "    if DEBUG_PRINT_FIRST and not printed_debug:\n",
    "        printed_debug = True\n",
    "        print(\"DEBUG sample (first processed slice): center=\", center)\n",
    "        print(\"  neighbor_idxs:\", neighbor_idxs)\n",
    "        print(\"  used_idxs sample:\", used[:8])\n",
    "        print(\"  shifts_used sample:\", shifts_used[:8])\n",
    "        print(\"  errs_used sample:\", errs_used[:8])\n",
    "    if (count+1) % 50 == 0:\n",
    "        print(f\"Processed {count+1}/{len(target_slices)} target slices (last center={center})\")\n",
    "\n",
    "# ---------- save results ----------\n",
    "if len(imgs_out) > 0:\n",
    "    imgs_arr = np.stack(imgs_out, axis=0)         # (N,H,W)\n",
    "    conf_arr = np.stack(confs_out, axis=0)         # (N,H,W)\n",
    "    np.savez_compressed(OUT_NPZ,\n",
    "                        indices=np.array(indices_out, dtype=np.int32),\n",
    "                        imgs=imgs_arr.astype(np.float32),\n",
    "                        confs=conf_arr.astype(np.float32),\n",
    "                        used_frames=np.array(used_frames_out, dtype=object),\n",
    "                        shifts=np.array(shifts_out, dtype=object),\n",
    "                        errs=np.array(errs_out, dtype=object))\n",
    "    with open(SUMMARY_JSON, \"w\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    print(\"Saved improved pseudos ->\", OUT_NPZ)\n",
    "    print(\"Saved summary ->\", SUMMARY_JSON)\n",
    "    print(\"Saved QA visuals (up to {}) ->\".format(VIS_COUNT), VIS_DIR)\n",
    "else:\n",
    "    print(\"No pseudo images created - check parameters / input stack\")\n",
    "\n",
    "print(\"Done. Total time: {:.1f}s\".format(time.time() - t0_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c3c6596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 260 pseudo-clean targets from pseudo_clean_improved.npz\n",
      "Saved baseline results -> oct_denoise_outputs/results_baselines.csv\n",
      "\n",
      "=== Mean image metrics (vs pseudo-clean target) ===\n",
      "PSNR  - raw: 23.080, median: 24.715, nlm: 25.469\n",
      "SSIM  - raw: 0.515, median: 0.606, nlm: 0.670\n",
      "\n",
      "=== Mean boundary localization error (pixels) ===\n",
      "BE - raw: 5.578, median: 5.560, nlm: 5.687\n",
      "\n",
      "Saved example visuals to: oct_denoise_outputs/baseline_visuals\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Baseline denoisers + evaluation (image metrics + anatomical boundary error)\n",
    "# - Loads pseudo_clean_subset.npz (indices, imgs)\n",
    "# - For each slice: apply median filter and Non-Local Means (NLM)\n",
    "# - Compute PSNR and SSIM vs pseudo-clean; compute boundary localization error (using annotations.json)\n",
    "# - Save results CSV and a few before/after visual examples into OUT_DIR/baseline_visuals\n",
    "\n",
    "import numpy as np, json, os, csv\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import median_filter\n",
    "try:\n",
    "    from skimage.restoration import denoise_nl_means\n",
    "    from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "    from skimage import filters\n",
    "except Exception as e:\n",
    "    raise ImportError(\"Requires scikit-image (denoise_nl_means, metrics). Install `pip install scikit-image`.\") from e\n",
    "\n",
    "# Paths\n",
    "OUT_DIR = Path(OUT_DIR) if isinstance(OUT_DIR, (str, Path)) else Path(\"./oct_denoise_outputs\")\n",
    "DATA_ROOT = Path(DATA_ROOT) if isinstance(DATA_ROOT, (str, Path)) else Path(\"./data\")\n",
    "npz_path = OUT_DIR / \"pseudo_clean_improved.npz\"\n",
    "ann_path = OUT_DIR / \"annotations.json\"\n",
    "tif_list = sorted(list(Path(DATA_ROOT).rglob(\"*.tif\")) + list(Path(DATA_ROOT).rglob(\"*.tiff\")))\n",
    "if not npz_path.exists():\n",
    "    raise FileNotFoundError(\"pseudo_clean_subset.npz not found in OUT_DIR. Run pseudo-creation cell first.\")\n",
    "if not ann_path.exists():\n",
    "    raise FileNotFoundError(\"annotations.json not found in OUT_DIR. Run annotation cell first.\")\n",
    "if not tif_list:\n",
    "    raise FileNotFoundError(\"No TIFF found under DATA_ROOT.\")\n",
    "\n",
    "# Parameters (tweak for speed/quality)\n",
    "MEDIAN_SIZE = 3           # median filter window\n",
    "NLM_PATCH_SIZE = 5\n",
    "NLM_PATCH_DISTANCE = 6\n",
    "NLM_H = 0.08              # denoising strength (relative to image range 0..1)\n",
    "NLM_FAST = True           # fast mode\n",
    "MAX_SAMPLES = None        # limit processed slices (None => all pseudo-clean slices)\n",
    "VISUAL_EXAMPLES = 12      # save up to this many before/after visual panels\n",
    "\n",
    "# Load data\n",
    "npz = np.load(npz_path, allow_pickle=True)\n",
    "indices = npz[\"indices\"].astype(int).tolist()\n",
    "pseudo_imgs = npz[\"imgs\"]   # shape (N, H, W)\n",
    "print(\"Loaded\", len(indices), \"pseudo-clean targets from\", npz_path.name)\n",
    "\n",
    "with open(ann_path, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# load stack (for raw images)\n",
    "tif_path = tif_list[0]\n",
    "import tifffile\n",
    "stack = tifffile.imread(str(tif_path)).astype(np.float32)\n",
    "\n",
    "# helper: boundary localization error using vertical sobel (as earlier)\n",
    "def boundary_localization_error(denoised_img, curves, window=10):\n",
    "    gy = np.abs(filters.sobel_v(denoised_img))\n",
    "    errs = []\n",
    "    for (x_arr, y_arr) in curves:\n",
    "        xs = np.rint(x_arr).astype(int)\n",
    "        ys = np.rint(y_arr).astype(int)\n",
    "        valid = (xs>=0) & (xs<denoised_img.shape[1])\n",
    "        xs = xs[valid]; ys = ys[valid]\n",
    "        if xs.size==0:\n",
    "            continue\n",
    "        col_positions = []\n",
    "        for col, ytrue in zip(xs, ys):\n",
    "            lo = int(max(0, ytrue-window)); hi = int(min(denoised_img.shape[0], ytrue+window+1))\n",
    "            patch = gy[lo:hi, col]\n",
    "            if patch.size==0:\n",
    "                col_positions.append(ytrue)\n",
    "            else:\n",
    "                rel = np.argmax(patch)\n",
    "                y_est = lo + rel\n",
    "                col_positions.append(y_est)\n",
    "        col_positions = np.array(col_positions)\n",
    "        errs.append(np.mean(np.abs(col_positions - ys)))\n",
    "    if len(errs)==0:\n",
    "        return None\n",
    "    return float(np.mean(errs))\n",
    "\n",
    "# iterate slices and compute metrics\n",
    "results = []\n",
    "visuals_saved = 0\n",
    "visual_dir = OUT_DIR / \"baseline_visuals\"\n",
    "visual_dir.mkdir(exist_ok=True)\n",
    "\n",
    "sample_list = indices if MAX_SAMPLES is None else indices[:MAX_SAMPLES]\n",
    "for i, idx in enumerate(sample_list):\n",
    "    raw = stack[idx].astype(np.float32)\n",
    "    pseudo = pseudo_imgs[i].astype(np.float32)\n",
    "\n",
    "    # normalize images to [0,1] for NLM and metrics (preserve dynamic range for PSNR)\n",
    "    raw01 = (raw - raw.min()) / (raw.max() - raw.min() + 1e-9)\n",
    "    pseudo01 = (pseudo - pseudo.min()) / (pseudo.max() - pseudo.min() + 1e-9)\n",
    "\n",
    "    # Baseline 1: median filter\n",
    "    med = median_filter(raw, size=(MEDIAN_SIZE, MEDIAN_SIZE)).astype(np.float32)\n",
    "    med01 = (med - med.min()) / (med.max() - med.min() + 1e-9)\n",
    "\n",
    "    # Baseline 2: NLM (on normalized image)\n",
    "    try:\n",
    "        nlm01 = denoise_nl_means(raw01, patch_size=NLM_PATCH_SIZE,\n",
    "                                 patch_distance=NLM_PATCH_DISTANCE, h=NLM_H, fast_mode=NLM_FAST, multichannel=False)\n",
    "    except TypeError:\n",
    "        # older versions use different arg names; try without multichannel\n",
    "        nlm01 = denoise_nl_means(raw01, patch_size=NLM_PATCH_SIZE,\n",
    "                                 patch_distance=NLM_PATCH_DISTANCE, h=NLM_H, fast_mode=NLM_FAST)\n",
    "    # rescale nlm back to raw range if needed\n",
    "    nlm = (nlm01 - nlm01.min()) / (nlm01.max() - nlm01.min() + 1e-9) * (raw.max()-raw.min()) + raw.min()\n",
    "    nlm01 = (nlm - nlm.min()) / (nlm.max() - nlm.min() + 1e-9)\n",
    "\n",
    "    # Compute image metrics vs pseudo-clean (use pseudo as reference)\n",
    "    # PSNR expects data_range; use pseudo.max()-pseudo.min()\n",
    "    data_range = float(pseudo.max() - pseudo.min())\n",
    "    med_psnr = psnr(pseudo, med, data_range=data_range)\n",
    "    nlm_psnr = psnr(pseudo, nlm, data_range=data_range)\n",
    "    raw_psnr = psnr(pseudo, raw, data_range=data_range)\n",
    "\n",
    "    med_ssim = ssim(pseudo, med, data_range=data_range)\n",
    "    nlm_ssim = ssim(pseudo, nlm, data_range=data_range)\n",
    "    raw_ssim = ssim(pseudo, raw, data_range=data_range)\n",
    "\n",
    "    # Anatomical metric: boundary localization error for annotated curves on this slice\n",
    "    ann_curves = annotations.get(str(idx), None)\n",
    "    be_raw = boundary_localization_error(raw, ann_curves) if ann_curves else None\n",
    "    be_med = boundary_localization_error(med, ann_curves) if ann_curves else None\n",
    "    be_nlm = boundary_localization_error(nlm, ann_curves) if ann_curves else None\n",
    "\n",
    "    results.append({\n",
    "        \"slice_index\": int(idx),\n",
    "        \"raw_psnr\": float(raw_psnr), \"med_psnr\": float(med_psnr), \"nlm_psnr\": float(nlm_psnr),\n",
    "        \"raw_ssim\": float(raw_ssim), \"med_ssim\": float(med_ssim), \"nlm_ssim\": float(nlm_ssim),\n",
    "        \"be_raw\": be_raw, \"be_med\": be_med, \"be_nlm\": be_nlm\n",
    "    })\n",
    "\n",
    "    # save visual examples (first VISUAL_EXAMPLES)\n",
    "    if visuals_saved < VISUAL_EXAMPLES:\n",
    "        fig, axs = plt.subplots(1,4, figsize=(16,6))\n",
    "        axs[0].imshow(raw, cmap='gray'); axs[0].set_title(f\"Raw (slice {idx})\"); axs[0].axis('off')\n",
    "        axs[1].imshow(pseudo, cmap='gray'); axs[1].set_title(\"Pseudo-clean (target)\"); axs[1].axis('off')\n",
    "        axs[2].imshow(med, cmap='gray'); axs[2].set_title(f\"Median\\nPSNR={med_psnr:.2f}, BE={be_med}\"); axs[2].axis('off')\n",
    "        axs[3].imshow(nlm, cmap='gray'); axs[3].set_title(f\"NLM\\nPSNR={nlm_psnr:.2f}, BE={be_nlm}\"); axs[3].axis('off')\n",
    "        # overlay annotation curves on pseudo for reference\n",
    "        if ann_curves:\n",
    "            for curve in ann_curves:\n",
    "                x,y = curve\n",
    "                axs[1].plot(x, y, '-r', linewidth=1)\n",
    "                axs[2].plot(x, y, '-r', linewidth=1)\n",
    "                axs[3].plot(x, y, '-r', linewidth=1)\n",
    "        outv = visual_dir / f\"baseline_vis_{idx:04d}.png\"\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(outv, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        visuals_saved += 1\n",
    "\n",
    "# Save results CSV\n",
    "csv_out = OUT_DIR / \"results_baselines.csv\"\n",
    "with open(csv_out, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(results[0].keys()))\n",
    "    writer.writeheader()\n",
    "    writer.writerows(results)\n",
    "print(\"Saved baseline results ->\", csv_out)\n",
    "\n",
    "# Print summary statistics (mean across slices, ignoring None)\n",
    "def mean_ignore_none(arr):\n",
    "    vals = [v for v in arr if v is not None]\n",
    "    return float(np.mean(vals)) if vals else None\n",
    "\n",
    "raw_psnrs = [r[\"raw_psnr\"] for r in results]\n",
    "med_psnrs = [r[\"med_psnr\"] for r in results]\n",
    "nlm_psnrs = [r[\"nlm_psnr\"] for r in results]\n",
    "raw_ssims = [r[\"raw_ssim\"] for r in results]\n",
    "med_ssims = [r[\"med_ssim\"] for r in results]\n",
    "nlm_ssims = [r[\"nlm_ssim\"] for r in results]\n",
    "\n",
    "be_raws = [r[\"be_raw\"] for r in results if r[\"be_raw\"] is not None]\n",
    "be_meds = [r[\"be_med\"] for r in results if r[\"be_med\"] is not None]\n",
    "be_nlms = [r[\"be_nlm\"] for r in results if r[\"be_nlm\"] is not None]\n",
    "\n",
    "print(\"\\n=== Mean image metrics (vs pseudo-clean target) ===\")\n",
    "print(f\"PSNR  - raw: {np.mean(raw_psnrs):.3f}, median: {np.mean(med_psnrs):.3f}, nlm: {np.mean(nlm_psnrs):.3f}\")\n",
    "print(f\"SSIM  - raw: {np.mean(raw_ssims):.3f}, median: {np.mean(med_ssims):.3f}, nlm: {np.mean(nlm_ssims):.3f}\")\n",
    "\n",
    "if be_raws:\n",
    "    print(\"\\n=== Mean boundary localization error (pixels) ===\")\n",
    "    print(f\"BE - raw: {np.mean(be_raws):.3f}, median: {np.mean(be_meds):.3f}, nlm: {np.mean(be_nlms):.3f}\")\n",
    "\n",
    "print(\"\\nSaved example visuals to:\", visual_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a239aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n",
      "Raw stack: Intensity.tif shape: (339, 806, 500)\n",
      "Loaded 260 pseudo-clean targets from pseudo_clean_improved.npz\n",
      "Train samples: 221, Val samples: 39, Val full-slices: 39\n",
      "Epoch 1/20  train_loss=0.1096 val_patch_loss=0.0937 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.459842123558047 mean_ssim=0.6603095807046554 mean_be=7.143664939557795 saved=True time=54.4s\n",
      "  slice 40  ps= 24.52741113218312  ss= 0.6538476426477776  be= 7.512499999999999\n",
      "  slice 54  ps= 26.598463765645345  ss= 0.6850156281443891  be= 7.5275\n",
      "  slice 93  ps= 26.51845889663395  ss= 0.6624479174816245  be= 7.69625\n",
      "  slice 99  ps= 24.48760540540194  ss= 0.6556070858222166  be= 7.57375\n",
      "  slice 104  ps= 27.37059081131683  ss= 0.6670788705609234  be= 7.50375\n",
      "  slice 112  ps= 26.904229859215015  ss= 0.6997827881238587  be= 7.100088383838384\n",
      "Epoch 2/20  train_loss=0.0884 val_patch_loss=0.0893 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.611076968513625 mean_ssim=0.6625670400323805 mean_be=7.093194272658558 saved=True time=59.5s\n",
      "  slice 40  ps= 24.756951983248502  ss= 0.6877673821169338  be= 7.36625\n",
      "  slice 54  ps= 27.69146109452489  ss= 0.7021378761067216  be= 7.112500000000001\n",
      "  slice 93  ps= 27.21076521676004  ss= 0.67269206036178  be= 7.422499999999999\n",
      "  slice 99  ps= 23.994385975678348  ss= 0.6538203608789057  be= 7.62375\n",
      "  slice 104  ps= 27.27511582509861  ss= 0.6640945091199052  be= 7.147499999999999\n",
      "  slice 112  ps= 27.352904145669367  ss= 0.7034276291132133  be= 6.958257575757576\n",
      "Epoch 3/20  train_loss=0.0857 val_patch_loss=0.0874 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.967970628789246 mean_ssim=0.6658879408204054 mean_be=7.065260652046366 saved=True time=54.8s\n",
      "  slice 40  ps= 25.697317667134474  ss= 0.6487879590132661  be= 7.35375\n",
      "  slice 54  ps= 26.80368295590458  ss= 0.6718435960575544  be= 7.195\n",
      "  slice 93  ps= 26.410216835742155  ss= 0.6609697292193106  be= 7.71875\n",
      "  slice 99  ps= 24.975515760402118  ss= 0.6537307663894287  be= 7.2575\n",
      "  slice 104  ps= 27.678381419214023  ss= 0.6551014667005195  be= 6.93125\n",
      "  slice 112  ps= 27.07706057835404  ss= 0.7102201870852533  be= 6.7095580808080815\n",
      "Epoch 4/20  train_loss=0.0839 val_patch_loss=0.0861 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.887886430095516 mean_ssim=0.6714168006441679 mean_be=6.953966503073646 saved=True time=52.0s\n",
      "  slice 40  ps= 26.481867572879686  ss= 0.6741499830755121  be= 7.29\n",
      "  slice 54  ps= 27.22693016130318  ss= 0.6877702075361433  be= 7.043749999999999\n",
      "  slice 93  ps= 26.29702909299243  ss= 0.6614047259617126  be= 7.48125\n",
      "  slice 99  ps= 24.730636431790558  ss= 0.6404469752721517  be= 7.40125\n",
      "  slice 104  ps= 27.768398628000565  ss= 0.6544569402420448  be= 6.91625\n",
      "  slice 112  ps= 27.726213455038618  ss= 0.701768954134083  be= 6.984621212121212\n",
      "Epoch 5/20  train_loss=0.0830 val_patch_loss=0.0858 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.99395907479029 mean_ssim=0.671149481421223 mean_be=6.865221412185699 saved=True time=55.8s\n",
      "  slice 40  ps= 26.513379765115545  ss= 0.7160173331790424  be= 7.30125\n",
      "  slice 54  ps= 27.432388607653788  ss= 0.7136612896016881  be= 6.9712499999999995\n",
      "  slice 93  ps= 26.64808083399481  ss= 0.6794199122749188  be= 7.50375\n",
      "  slice 99  ps= 24.56574742174209  ss= 0.6599125034148531  be= 7.25125\n",
      "  slice 104  ps= 28.0179461172622  ss= 0.6755212599797218  be= 6.885\n",
      "  slice 112  ps= 28.46717472128976  ss= 0.7134257957158552  be= 6.888800505050505\n",
      "Epoch 6/20  train_loss=0.0818 val_patch_loss=0.0840 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.20401171879701 mean_ssim=0.6861829830999209 mean_be=6.809900238650237 saved=True time=52.8s\n",
      "  slice 40  ps= 26.015919195713778  ss= 0.7113443297343333  be= 7.123749999999999\n",
      "  slice 54  ps= 27.713040500902636  ss= 0.715529095365133  be= 6.8462499999999995\n",
      "  slice 93  ps= 27.186094835793607  ss= 0.6780688018250692  be= 7.21875\n",
      "  slice 99  ps= 24.44059291291068  ss= 0.6467142434014594  be= 7.334999999999999\n",
      "  slice 104  ps= 27.95653900957502  ss= 0.6684977407424806  be= 6.692500000000001\n",
      "  slice 112  ps= 27.90028982221395  ss= 0.7234894446635326  be= 6.8016161616161614\n",
      "Epoch 7/20  train_loss=0.0809 val_patch_loss=0.0851 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.996254430868774 mean_ssim=0.6839126727546334 mean_be=6.754197852412138 saved=True time=56.2s\n",
      "  slice 40  ps= 26.667488816659205  ss= 0.7303862321311188  be= 7.10125\n",
      "  slice 54  ps= 25.9719214534627  ss= 0.7120338069350081  be= 7.00375\n",
      "  slice 93  ps= 25.81173769825138  ss= 0.6783423490118804  be= 6.9725\n",
      "  slice 99  ps= 25.814709584378654  ss= 0.6889604131670264  be= 7.06625\n",
      "  slice 104  ps= 27.623777093995137  ss= 0.6952276490311374  be= 6.71625\n",
      "  slice 112  ps= 26.941580863669444  ss= 0.7205111149530374  be= 6.633535353535354\n",
      "Epoch 8/20  train_loss=0.0808 val_patch_loss=0.0828 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.486238975093745 mean_ssim=0.6882962391951322 mean_be=6.7716716947074085 saved=False time=51.6s\n",
      "  slice 40  ps= 26.25144342003818  ss= 0.7214043043633759  be= 7.0925\n",
      "  slice 54  ps= 27.50345741507973  ss= 0.7181254960846755  be= 7.050000000000001\n",
      "  slice 93  ps= 27.06741134130322  ss= 0.6870349953036335  be= 7.3775\n",
      "  slice 99  ps= 24.89580219453984  ss= 0.6766262688336694  be= 7.0675\n",
      "  slice 104  ps= 28.37129703771857  ss= 0.6947725217510947  be= 6.835\n",
      "  slice 112  ps= 27.93191794475487  ss= 0.7246317778702985  be= 6.739532828282828\n",
      "Epoch 9/20  train_loss=0.0800 val_patch_loss=0.0827 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.366680030040843 mean_ssim=0.6895130690804331 mean_be=6.7292067588496165 saved=True time=52.5s\n",
      "  slice 40  ps= 26.46068510995996  ss= 0.7293807355950204  be= 7.0625\n",
      "  slice 54  ps= 26.84920852902199  ss= 0.7141723921090866  be= 7.14875\n",
      "  slice 93  ps= 26.618689054097942  ss= 0.6838896297178313  be= 7.0775\n",
      "  slice 99  ps= 25.19587547144099  ss= 0.6825310312565829  be= 6.878749999999999\n",
      "  slice 104  ps= 28.18656083966179  ss= 0.6976050393726964  be= 6.905\n",
      "  slice 112  ps= 27.64419042949507  ss= 0.725291786691611  be= 6.677247474747475\n",
      "Epoch 10/20  train_loss=0.0797 val_patch_loss=0.0846 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=26.92403501577528 mean_ssim=0.6871730693648097 mean_be=6.732101628530201 saved=False time=49.6s\n",
      "  slice 40  ps= 26.215081776941208  ss= 0.7101732848400335  be= 7.24125\n",
      "  slice 54  ps= 25.89446805065554  ss= 0.7009780322093303  be= 7.1187499999999995\n",
      "  slice 93  ps= 25.762902021399636  ss= 0.6724459101823875  be= 7.05875\n",
      "  slice 99  ps= 25.342410487722496  ss= 0.6719553604314685  be= 6.93375\n",
      "  slice 104  ps= 27.3813430007851  ss= 0.6878261557235046  be= 6.7524999999999995\n",
      "  slice 112  ps= 26.42379236575325  ss= 0.7155089817501769  be= 6.79219696969697\n",
      "Epoch 11/20  train_loss=0.0794 val_patch_loss=0.0833 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.325803190515 mean_ssim=0.677025492091127 mean_be=6.745076253111967 saved=False time=51.7s\n",
      "  slice 40  ps= 25.820566760917615  ss= 0.7009135207869034  be= 7.1875\n",
      "  slice 54  ps= 27.040610718296207  ss= 0.6913858137831164  be= 7.0875\n",
      "  slice 93  ps= 26.888863588736747  ss= 0.6668206275869032  be= 6.97625\n",
      "  slice 99  ps= 24.89122804969877  ss= 0.6524609532872714  be= 7.137499999999999\n",
      "  slice 104  ps= 28.039380209419292  ss= 0.6688367558768062  be= 6.7524999999999995\n",
      "  slice 112  ps= 26.998254671130354  ss= 0.7033780028266677  be= 6.627095959595959\n",
      "Epoch 12/20  train_loss=0.0780 val_patch_loss=0.0828 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.24655510117941 mean_ssim=0.692203469966293 mean_be=6.7281816860388295 saved=True time=54.9s\n",
      "  slice 40  ps= 27.05603820922143  ss= 0.7356368097645867  be= 7.081250000000001\n",
      "  slice 54  ps= 26.90124558336246  ss= 0.7193614245106903  be= 7.03125\n",
      "  slice 93  ps= 26.52616963204072  ss= 0.6882162137979945  be= 6.936249999999999\n",
      "  slice 99  ps= 25.201015281450296  ss= 0.6903957101080805  be= 7.0975\n",
      "  slice 104  ps= 28.10715460022772  ss= 0.70140806566536  be= 6.8325\n",
      "  slice 112  ps= 28.23699845857062  ss= 0.7303293678280577  be= 6.568623737373738\n",
      "Epoch 13/20  train_loss=0.0777 val_patch_loss=0.0810 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.40897058485297 mean_ssim=0.694722510261493 mean_be=6.770742551099693 saved=False time=49.6s\n",
      "  slice 40  ps= 25.66820368376699  ss= 0.7210871667068495  be= 7.16375\n",
      "  slice 54  ps= 27.582489542085796  ss= 0.7211602314279303  be= 7.2162500000000005\n",
      "  slice 93  ps= 27.314276833750736  ss= 0.6928381548692335  be= 7.00625\n",
      "  slice 99  ps= 24.448551533382094  ss= 0.6768885726004386  be= 7.29375\n",
      "  slice 104  ps= 28.158494501113196  ss= 0.7012150021822309  be= 7.02\n",
      "  slice 112  ps= 27.25989872198832  ss= 0.7272955227525234  be= 6.556111111111111\n",
      "Epoch 14/20  train_loss=0.0779 val_patch_loss=0.0821 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.30804169901722 mean_ssim=0.68513198245551 mean_be=6.684501160215445 saved=True time=50.5s\n",
      "  slice 40  ps= 26.282733176732343  ss= 0.7087547879602194  be= 7.0337499999999995\n",
      "  slice 54  ps= 27.105734616848093  ss= 0.7036173866407599  be= 7.133749999999999\n",
      "  slice 93  ps= 26.627956223903297  ss= 0.6738490380419329  be= 6.99375\n",
      "  slice 99  ps= 24.891643143325176  ss= 0.6632723855500068  be= 6.9975000000000005\n",
      "  slice 104  ps= 28.136292100799082  ss= 0.6848636976985811  be= 6.95875\n",
      "  slice 112  ps= 27.060649668995538  ss= 0.7188582677217584  be= 6.460669191919192\n",
      "Epoch 15/20  train_loss=0.0777 val_patch_loss=0.0812 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.438238837082945 mean_ssim=0.6878689324011157 mean_be=6.676799576085289 saved=True time=50.5s\n",
      "  slice 40  ps= 25.86549574073971  ss= 0.7160734992525165  be= 7.0075\n",
      "  slice 54  ps= 27.888153059656254  ss= 0.7177560798048175  be= 6.88625\n",
      "  slice 93  ps= 27.50518604255689  ss= 0.6887915594759416  be= 6.88125\n",
      "  slice 99  ps= 24.42505065043566  ss= 0.6695704900076394  be= 7.275\n",
      "  slice 104  ps= 28.297108265932927  ss= 0.6932511582405556  be= 6.84375\n",
      "  slice 112  ps= 27.884263054358478  ss= 0.7209969127368687  be= 6.579848484848485\n",
      "Epoch 16/20  train_loss=0.0766 val_patch_loss=0.0805 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.41718580334996 mean_ssim=0.6804815201032317 mean_be=6.691562762634192 saved=False time=54.4s\n",
      "  slice 40  ps= 26.561179910730566  ss= 0.7285326938511455  be= 7.03875\n",
      "  slice 54  ps= 27.23373881695401  ss= 0.7137507390610801  be= 7.001250000000001\n",
      "  slice 93  ps= 26.763847584067847  ss= 0.6786027495054721  be= 6.9425\n",
      "  slice 99  ps= 25.059822584883328  ss= 0.6731080943455224  be= 7.1975\n",
      "  slice 104  ps= 28.27196432865974  ss= 0.6902499851048443  be= 6.907500000000001\n",
      "  slice 112  ps= 27.422169578343663  ss= 0.7127595730040225  be= 6.455984848484849\n",
      "Epoch 17/20  train_loss=0.0767 val_patch_loss=0.0804 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.507168765224826 mean_ssim=0.6898968821500674 mean_be=6.754100568743424 saved=False time=55.7s\n",
      "  slice 40  ps= 27.028711060447932  ss= 0.7164808896649102  be= 6.98625\n",
      "  slice 54  ps= 27.28870302385504  ss= 0.7080112931716187  be= 6.955\n",
      "  slice 93  ps= 26.815888243721826  ss= 0.6747892238644548  be= 6.75625\n",
      "  slice 99  ps= 25.134937068647897  ss= 0.6611488671776259  be= 7.05625\n",
      "  slice 104  ps= 28.547280928930245  ss= 0.6847274421839996  be= 6.85\n",
      "  slice 112  ps= 28.292661673547546  ss= 0.7250899656067228  be= 6.446830808080808\n",
      "Epoch 18/20  train_loss=0.0763 val_patch_loss=0.0803 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.4381569899449 mean_ssim=0.6887640078794012 mean_be=6.730838731374447 saved=False time=53.7s\n",
      "  slice 40  ps= 26.512861034385836  ss= 0.725072472434269  be= 6.91125\n",
      "  slice 54  ps= 26.864027199031163  ss= 0.713121113972865  be= 6.79875\n",
      "  slice 93  ps= 26.538207993362597  ss= 0.6800962137336275  be= 6.945\n",
      "  slice 99  ps= 25.27171068023651  ss= 0.6796034133513831  be= 7.06625\n",
      "  slice 104  ps= 28.18087284746597  ss= 0.6958686557327491  be= 6.895\n",
      "  slice 112  ps= 27.209582770775548  ss= 0.7163616297400229  be= 6.454507575757575\n",
      "Epoch 19/20  train_loss=0.0763 val_patch_loss=0.0800 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.445207502514723 mean_ssim=0.6909358205081142 mean_be=6.66077713952714 saved=True time=48.8s\n",
      "  slice 40  ps= 26.924962220121373  ss= 0.7213384817540802  be= 6.94375\n",
      "  slice 54  ps= 27.411891235490394  ss= 0.7164997298193032  be= 6.9925\n",
      "  slice 93  ps= 26.92538313902139  ss= 0.6873578106249019  be= 6.965\n",
      "  slice 99  ps= 24.973348114546567  ss= 0.6761543453062256  be= 7.24\n",
      "  slice 104  ps= 28.49478781660285  ss= 0.6974081883312531  be= 6.862500000000001\n",
      "  slice 112  ps= 28.413733782173743  ss= 0.7245903977466497  be= 6.44739898989899\n",
      "Epoch 20/20  train_loss=0.0764 val_patch_loss=0.0803 valid_ps_count=39 valid_ss_count=39 be_count=39 mean_psnr=27.4799488668319 mean_ssim=0.6929257570020655 mean_be=6.6245426597212305 saved=True time=52.9s\n",
      "  slice 40  ps= 26.694665570820582  ss= 0.7304288648741455  be= 6.96125\n",
      "  slice 54  ps= 26.867035150909942  ss= 0.7149536921943922  be= 6.75\n",
      "  slice 93  ps= 26.513633036951166  ss= 0.6842013737277883  be= 6.9175\n",
      "  slice 99  ps= 25.473506199546932  ss= 0.6887238564696816  be= 6.97625\n",
      "  slice 104  ps= 28.313892235009106  ss= 0.7009189682727456  be= 6.82625\n",
      "  slice 112  ps= 27.272593742925572  ss= 0.72109474822807  be= 6.306464646464646\n",
      "Finished. Best-checkpoint: oct_denoise_outputs/unet_smoke_fullimage_groupnorm.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, time, random, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from skimage.metrics import structural_similarity as sk_ssim\n",
    "from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage as ndi    # << ADDED\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "OUT_DIR = Path(\"./oct_denoise_outputs\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DATA_ROOT = Path(\"./data\")\n",
    "NPZ_PATH = OUT_DIR / \"pseudo_clean_improved.npz\"\n",
    "ANN_PATH = OUT_DIR / \"annotations.json\"\n",
    "\n",
    "EPOCHS = 20         # smoke default\n",
    "BATCH_SIZE = 1        # M1-friendly\n",
    "LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "EDGE_LOSS_WEIGHT = 0.35\n",
    "VAL_FRACTION = 0.15\n",
    "SEED = 1337\n",
    "CKPT_PATH = OUT_DIR / \"unet_smoke_fullimage_groupnorm.pth\"\n",
    "EXAMPLES_DIR = OUT_DIR / \"examples\"\n",
    "EXAMPLES_DIR.mkdir(exist_ok=True)\n",
    "EPS = 1e-9\n",
    "PIXEL_SIZE_UM = None   # set to physical pixel spacing if available to convert BE to microns\n",
    "\n",
    "# ---------- BE weighting params (minimal additions) ----------\n",
    "BE_SIGMA_PX = 3.0       # gaussian sigma (band width)\n",
    "BE_MAX_WEIGHT = 6.0     # maximum multiplier near boundary\n",
    "BE_MIN_WEIGHT = 1.0     # baseline multiplier away from boundary\n",
    "BE_LOSS_WEIGHT = 0.0    # keep separate term small for now (you can increase). use 0.0 to start.\n",
    "\n",
    "# ---------- device ----------\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "print(\"Device:\", DEVICE)\n",
    "\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
    "\n",
    "# ---------- load data ----------\n",
    "if not NPZ_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing {NPZ_PATH}. Create pseudo targets first.\")\n",
    "npz = np.load(str(NPZ_PATH), allow_pickle=True)\n",
    "pseudo_indices = npz[\"indices\"].astype(int).tolist()\n",
    "pseudo_imgs = npz[\"imgs\"].astype(np.float32)\n",
    "\n",
    "# load first TIFF stack under DATA_ROOT\n",
    "tif_list = sorted(list(Path(DATA_ROOT).rglob(\"*.tif\")) + list(Path(DATA_ROOT).rglob(\"*.tiff\")))\n",
    "if not tif_list:\n",
    "    raise FileNotFoundError(\"No TIFFs found under DATA_ROOT: \" + str(DATA_ROOT))\n",
    "stack = tifffile.imread(str(tif_list[0])).astype(np.float32)   # (S, H, W)\n",
    "S, H, W = stack.shape\n",
    "print(\"Raw stack:\", tif_list[0].name, \"shape:\", stack.shape)\n",
    "print(\"Loaded\", len(pseudo_imgs), \"pseudo-clean targets from\", NPZ_PATH.name)\n",
    "\n",
    "with open(ANN_PATH, \"r\") as f:\n",
    "    annotations = json.load(f)\n",
    "annotated_slices = sorted([int(k) for k in annotations.keys()])\n",
    "\n",
    "# ---------- PRECOMPUTE boundary weight maps (minimal addition) ----------\n",
    "# This creates boundary_weight_maps[s] where values are high near annotated boundaries.\n",
    "boundary_weight_maps = np.ones((S, H, W), dtype=np.float32) * BE_MIN_WEIGHT\n",
    "for s in range(S):\n",
    "    ann_curves = annotations.get(str(s), None)\n",
    "    if not ann_curves:\n",
    "        continue\n",
    "    bmap = np.zeros((H, W), dtype=np.uint8)\n",
    "    for (xcoords, ycoords) in ann_curves:\n",
    "        xs = np.rint(np.array(xcoords)).astype(int)\n",
    "        ys = np.rint(np.array(ycoords)).astype(int)\n",
    "        valid = (xs >= 0) & (xs < W) & (ys >= 0) & (ys < H)\n",
    "        xs = xs[valid]; ys = ys[valid]\n",
    "        if xs.size > 0:\n",
    "            bmap[ys, xs] = 1\n",
    "    if bmap.sum() == 0:\n",
    "        continue\n",
    "    dist = ndi.distance_transform_edt(1 - bmap)  # dist=0 at boundaries\n",
    "    weight = BE_MIN_WEIGHT + (BE_MAX_WEIGHT - BE_MIN_WEIGHT) * np.exp(-(dist**2) / (2 * (BE_SIGMA_PX**2)))\n",
    "    boundary_weight_maps[s] = weight\n",
    "# optionally save\n",
    "np.save(OUT_DIR / \"boundary_weight_maps.npy\", boundary_weight_maps)\n",
    "\n",
    "# prepare train/val positions (only positions with pseudo targets)\n",
    "all_positions = list(range(len(pseudo_indices)))\n",
    "train_pos, val_pos = train_test_split(all_positions, test_size=VAL_FRACTION, random_state=SEED)\n",
    "val_full_slices = sorted(list({pseudo_indices[p] for p in val_pos}))\n",
    "print(f\"Train samples: {len(train_pos)}, Val samples: {len(val_pos)}, Val full-slices: {len(val_full_slices)}\")\n",
    "\n",
    "# ---------- dataset (full images) ----------\n",
    "class FullSliceDataset(Dataset):\n",
    "    def __init__(self, pos_list, indices_map, pseudo_imgs, raw_stack):\n",
    "        self.pos_list = pos_list\n",
    "        self.indices_map = indices_map\n",
    "        self.pseudo = pseudo_imgs\n",
    "        self.raw = raw_stack\n",
    "    def __len__(self): return len(self.pos_list)\n",
    "    def __getitem__(self, idx):\n",
    "        pos = self.pos_list[idx]\n",
    "        slice_idx = int(self.indices_map[pos])\n",
    "        raw = self.raw[slice_idx].astype(np.float32)\n",
    "        tgt = self.pseudo[pos].astype(np.float32)\n",
    "        raw01 = (raw - raw.min()) / (raw.max() - raw.min() + EPS)\n",
    "        tgt01 = (tgt - tgt.min()) / (tgt.max() - tgt.min() + EPS)\n",
    "        x = torch.from_numpy(raw01[None,:,:]).float()\n",
    "        y = torch.from_numpy(tgt01[None,:,:]).float()\n",
    "        return x, y, slice_idx\n",
    "\n",
    "train_ds = FullSliceDataset(train_pos, pseudo_indices, pseudo_imgs, stack)\n",
    "val_ds   = FullSliceDataset(val_pos,   pseudo_indices, pseudo_imgs, stack)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, pin_memory=False)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "# ---------- small UNet with GroupNorm (stable for B=1) ----------\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        # choose groups that divide out_ch\n",
    "        def choose_groups(c):\n",
    "            for g in (8,4,2,1):\n",
    "                if c % g == 0:\n",
    "                    return g\n",
    "            return 1\n",
    "        groups = choose_groups(out_ch)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(groups, out_ch),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.ReLU(inplace=True),\n",
    "            nn.GroupNorm(groups, out_ch)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class SmallUNetFull(nn.Module):\n",
    "    def __init__(self, in_ch=1, base=16):\n",
    "        super().__init__()\n",
    "        self.enc1 = ConvBlock(in_ch, base)\n",
    "        self.enc2 = ConvBlock(base, base*2)\n",
    "        self.enc3 = ConvBlock(base*2, base*4)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        self.dec3 = ConvBlock(base*4, base*2)\n",
    "        self.dec2 = ConvBlock(base*2, base)\n",
    "        self.final = nn.Conv2d(base, 1, 1)\n",
    "    def forward(self, x):\n",
    "        H_in, W_in = x.shape[2], x.shape[3]\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool(e1))\n",
    "        e3 = self.enc3(self.pool(e2))\n",
    "        d = self.up(e3); d = self.dec3(d)\n",
    "        d = self.up(d); d = self.dec2(d)\n",
    "        out = self.final(d)\n",
    "        if out.shape[2] != H_in or out.shape[3] != W_in:\n",
    "            out = F.interpolate(out, size=(H_in, W_in), mode='bilinear', align_corners=False)\n",
    "        return out\n",
    "\n",
    "# ---------- edge operator & losses ----------\n",
    "def sobel_edges_torch(x):\n",
    "    Kx = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], dtype=torch.float32, device=x.device).reshape(1,1,3,3)\n",
    "    Ky = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], dtype=torch.float32, device=x.device).reshape(1,1,3,3)\n",
    "    gx = F.conv2d(x, Kx, padding=1); gy = F.conv2d(x, Ky, padding=1)\n",
    "    return torch.sqrt(gx*gx + gy*gy + 1e-12)\n",
    "\n",
    "l1_loss = nn.L1Loss()\n",
    "\n",
    "# ---------- metrics helpers (robust) ----------\n",
    "def manual_psnr_safe(ref, im, data_range=1.0):\n",
    "    if ref.shape != im.shape: return np.nan\n",
    "    if not np.isfinite(ref).all() or not np.isfinite(im).all(): return np.nan\n",
    "    if (ref.max() - ref.min()) < 1e-6: return np.nan\n",
    "    mse = float(np.mean((ref - im)**2))\n",
    "    if mse <= 0: return 100.0\n",
    "    return 10.0 * np.log10((data_range**2) / mse)\n",
    "\n",
    "\n",
    "def safe_ssim(ref, im, data_range=1.0):\n",
    "    try:\n",
    "        if (ref.max() - ref.min()) < 1e-6: return np.nan\n",
    "        return float(sk_ssim(ref, im, data_range=data_range))\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def compute_BE(pred_np, ann_curves):\n",
    "    if not ann_curves: return None\n",
    "    gy = np.abs(filters.sobel_v(pred_np))\n",
    "    errs = []\n",
    "    for (xcoords, ycoords) in ann_curves:\n",
    "        xs = np.rint(np.array(xcoords)).astype(int)\n",
    "        ys = np.rint(np.array(ycoords)).astype(int)\n",
    "        valid = (xs>=0) & (xs < pred_np.shape[1])\n",
    "        xs = xs[valid]; ys = ys[valid]\n",
    "        if xs.size == 0: continue\n",
    "        col_positions = []\n",
    "        for col, ytrue in zip(xs, ys):\n",
    "            lo = int(max(0, ytrue-12)); hi = int(min(pred_np.shape[0], ytrue+13))\n",
    "            patch = gy[lo:hi, col]\n",
    "            if patch.size == 0:\n",
    "                col_positions.append(ytrue)\n",
    "            else:\n",
    "                rel = np.argmax(patch); col_positions.append(lo + rel)\n",
    "        col_positions = np.array(col_positions)\n",
    "        if col_positions.size>0:\n",
    "            errs.append(np.mean(np.abs(col_positions - ys)))\n",
    "    return float(np.mean(errs)) if errs else None\n",
    "\n",
    "# ---------- model & optimizer ----------\n",
    "model = SmallUNetFull(in_ch=1, base=16).to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode='min', factor=0.5, patience=1, verbose=True)\n",
    "\n",
    "# ---------- utilities: save visual examples ----------\n",
    "def save_example(raw, tgt, pred, fname):\n",
    "    fig, axs = plt.subplots(1,4, figsize=(12,3))\n",
    "    axs[0].imshow(raw, cmap='gray'); axs[0].set_title('raw'); axs[0].axis('off')\n",
    "    axs[1].imshow(tgt, cmap='gray'); axs[1].set_title('target'); axs[1].axis('off')\n",
    "    axs[2].imshow(pred, cmap='gray'); axs[2].set_title('pred'); axs[2].axis('off')\n",
    "    axs[3].imshow(np.abs(pred - tgt), cmap='hot'); axs[3].set_title('abs diff'); axs[3].axis('off')\n",
    "    plt.tight_layout(); fig.savefig(str(fname), bbox_inches='tight'); plt.close(fig)\n",
    "\n",
    "# ---------- training loop (minimal edits to use bw_map) ----------\n",
    "best_be = float(\"inf\")\n",
    "history = {\"train_loss\":[], \"val_patch_loss\":[], \"val_psnr\":[], \"val_ssim\":[], \"val_be\":[]}\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running = 0.0; seen = 0\n",
    "    t0 = time.time()\n",
    "    for xb, yb, slice_idx in train_loader:   # << CHANGED: unpack slice_idx\n",
    "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "        # prepare boundary weight map for this slice (B=1 expected)\n",
    "        sidx = int(slice_idx) if isinstance(slice_idx, (int, np.integer)) else int(slice_idx.item())\n",
    "        bw = boundary_weight_maps[sidx]   # (H,W) numpy\n",
    "        bw_tensor = torch.from_numpy(bw).to(DEVICE)[None, None, :, :].float()  # (1,1,H,W)\n",
    "        pred = model(xb)\n",
    "        # per-pixel L1 and edge diffs\n",
    "        int_l1 = torch.abs(pred - yb)                          # (B,1,H,W)\n",
    "        edge_l1 = torch.abs(sobel_edges_torch(pred) - sobel_edges_torch(yb))\n",
    "        # weighted losses\n",
    "        int_loss = (int_l1 * bw_tensor).mean()\n",
    "        edge_loss_local = (edge_l1 * bw_tensor).mean()\n",
    "        loss = int_loss + EDGE_LOSS_WEIGHT * edge_loss_local + BE_LOSS_WEIGHT * edge_loss_local\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "        running += loss.item() * xb.size(0); seen += xb.size(0)\n",
    "    train_loss = running / (seen if seen>0 else 1)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    t1 = time.time()\n",
    "\n",
    "    # validation patch loss (full-image here)\n",
    "    model.eval()\n",
    "    vrun = 0.0; vseen = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb, slice_idx in val_loader:   # << CHANGED: unpack slice_idx\n",
    "            xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "            sidx = int(slice_idx) if isinstance(slice_idx, (int, np.integer)) else int(slice_idx.item())\n",
    "            bw = boundary_weight_maps[sidx]\n",
    "            bw_tensor = torch.from_numpy(bw).to(DEVICE)[None, None, :, :].float()\n",
    "            pred = model(xb)\n",
    "            int_l1 = torch.abs(pred - yb)\n",
    "            edge_l1 = torch.abs(sobel_edges_torch(pred) - sobel_edges_torch(yb))\n",
    "            int_loss = (int_l1 * bw_tensor).mean()\n",
    "            edge_loss_local = (edge_l1 * bw_tensor).mean()\n",
    "            vloss = (int_loss + EDGE_LOSS_WEIGHT * edge_loss_local).item()\n",
    "            vrun += vloss * xb.size(0); vseen += xb.size(0)\n",
    "    val_patch_loss = vrun / (vseen if vseen>0 else 1)\n",
    "    history[\"val_patch_loss\"].append(val_patch_loss)\n",
    "\n",
    "    # full-slice eval on val_full_slices (unchanged)\n",
    "    ps_list = []; ss_list = []; be_list = []\n",
    "    per_slice = []\n",
    "    with torch.no_grad():\n",
    "        for s in val_full_slices:\n",
    "            raw = stack[s].astype(np.float32)\n",
    "            # find first pseudo patch that maps to this slice (if any)\n",
    "            pos_idx = [i for i,si in enumerate(pseudo_indices) if int(si) == int(s)]\n",
    "            tgt = None\n",
    "            if len(pos_idx) > 0:\n",
    "                tgt = pseudo_imgs[pos_idx[0]].astype(np.float32)\n",
    "            raw01 = (raw - raw.min())/(raw.max()-raw.min()+EPS)\n",
    "            x = torch.from_numpy(raw01[None,None,:,:]).float().to(DEVICE)\n",
    "            pred = model(x).detach().cpu().numpy()[0,0]\n",
    "            pred = np.clip(pred, 0.0, 1.0)\n",
    "\n",
    "            ps = ss = np.nan\n",
    "            if tgt is not None:\n",
    "                tgt01 = (tgt - tgt.min())/(tgt.max()-tgt.min()+EPS)\n",
    "                # if tgt is a different shape, center-pad/crop to pred shape\n",
    "                if tgt01.shape != pred.shape:\n",
    "                    ph, pw = tgt01.shape; H, W = pred.shape\n",
    "                    if ph <= H and pw <= W:\n",
    "                        canvas = np.zeros_like(pred); top = (H-ph)//2; left = (W-pw)//2\n",
    "                        canvas[top:top+ph, left:left+pw] = tgt01; tgt01 = canvas\n",
    "                    else:\n",
    "                        top = (ph-H)//2; left = (pw-W)//2\n",
    "                        tgt01 = tgt01[top:top+H, left:left+W]\n",
    "                ps = manual_psnr_safe(tgt01, pred, data_range=1.0)\n",
    "                ss = safe_ssim(tgt01, pred, data_range=1.0)\n",
    "                if np.isfinite(ps): ps_list.append(ps)\n",
    "                if np.isfinite(ss): ss_list.append(ss)\n",
    "\n",
    "            ann_curves = annotations.get(str(s), None)\n",
    "            be = compute_BE(pred, ann_curves)\n",
    "            if be is not None: be_list.append(be)\n",
    "            per_slice.append({\"slice\":int(s), \"ps\":ps, \"ss\":ss, \"be\":be})\n",
    "\n",
    "    mean_ps = float(np.nanmean(ps_list)) if len(ps_list)>0 else None\n",
    "    mean_ss = float(np.nanmean(ss_list)) if len(ss_list)>0 else None\n",
    "    mean_be = float(np.mean(be_list)) if len(be_list)>0 else None\n",
    "\n",
    "    history[\"val_psnr\"].append(mean_ps); history[\"val_ssim\"].append(mean_ss); history[\"val_be\"].append(mean_be)\n",
    "\n",
    "    # scheduler step (monitor val_patch_loss)\n",
    "    scheduler.step(val_patch_loss)\n",
    "\n",
    "    saved = False\n",
    "    if mean_be is not None and mean_be < best_be:\n",
    "        best_be = mean_be\n",
    "        torch.save(model.state_dict(), CKPT_PATH)\n",
    "        saved = True\n",
    "\n",
    "    print(f\"Epoch {epoch}/{EPOCHS}  train_loss={train_loss:.4f} val_patch_loss={val_patch_loss:.4f} \"\n",
    "          f\"valid_ps_count={len(ps_list)} valid_ss_count={len(ss_list)} be_count={len(be_list)} mean_psnr={mean_ps} mean_ssim={mean_ss} mean_be={mean_be} saved={saved} time={(t1-t0):.1f}s\")\n",
    "    for d in per_slice[:6]:\n",
    "        print(\"  slice\",d[\"slice\"], \" ps=\", d[\"ps\"], \" ss=\", d[\"ss\"], \" be=\", d[\"be\"]) \n",
    "\n",
    "    # save a few visual examples for quick QA\n",
    "    for i, s in enumerate(val_full_slices[:3]):\n",
    "        raw = stack[s].astype(np.float32)\n",
    "        raw01 = (raw - raw.min())/(raw.max()-raw.min()+EPS)\n",
    "        pos_idx = [i for i,si in enumerate(pseudo_indices) if int(si) == int(s)]\n",
    "        if pos_idx:\n",
    "            tgt = pseudo_imgs[pos_idx[0]].astype(np.float32)\n",
    "            tgt01 = (tgt - tgt.min())/(tgt.max()-tgt.min()+EPS)\n",
    "            # compute pred again (cheap)\n",
    "            x = torch.from_numpy(raw01[None,None,:,:]).float().to(DEVICE)\n",
    "            pred = model(x).detach().cpu().numpy()[0,0]\n",
    "            pred = np.clip(pred, 0.0, 1.0)\n",
    "            # pad/crop tgt01 to pred shape if necessary (same logic as above)\n",
    "            if tgt01.shape != pred.shape:\n",
    "                ph, pw = tgt01.shape; H, W = pred.shape\n",
    "                if ph <= H and pw <= W:\n",
    "                    canvas = np.zeros_like(pred); top = (H-ph)//2; left = (W-pw)//2\n",
    "                    canvas[top:top+ph, left:left+pw] = tgt01; tgt01 = canvas\n",
    "                else:\n",
    "                    top = (ph-H)//2; left = (pw-W)//2\n",
    "                    tgt01 = tgt01[top:top+H, left:left+W]\n",
    "            save_example(raw01, tgt01, pred, EXAMPLES_DIR / f\"epoch{epoch}_slice{s}.png\")\n",
    "\n",
    "# Save history\n",
    "with open(OUT_DIR / \"unet_smoke_fullimage_groupnorm_history.json\", \"w\") as f:\n",
    "    json.dump(history, f, indent=2)\n",
    "\n",
    "print(\"Finished. Best-checkpoint:\", CKPT_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
